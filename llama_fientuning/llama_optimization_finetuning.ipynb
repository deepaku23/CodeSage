{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2762e86616214f2098e62e2a6c21db3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3925f284d4eb49a48a99dce362ccfef6",
              "IPY_MODEL_cb4625bda1db4447bb39d11538f00775",
              "IPY_MODEL_0a2a53ce84954e56919d7386848d45c0"
            ],
            "layout": "IPY_MODEL_056f60c7ddaa43e09068d383f7b652bf"
          }
        },
        "3925f284d4eb49a48a99dce362ccfef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835c9939bfa3496cbe536b8e8bd5c392",
            "placeholder": "​",
            "style": "IPY_MODEL_9c7019e07fbe4282b8356483e34e01ea",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cb4625bda1db4447bb39d11538f00775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d9b9dd87cb7403b90e0a7e630bf3ede",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65bc84768754465a9aff8bf017e7c8cb",
            "value": 2
          }
        },
        "0a2a53ce84954e56919d7386848d45c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_626c3eb81b4e4697b2ea217bf11735aa",
            "placeholder": "​",
            "style": "IPY_MODEL_d8259bdf307a46f38c70d3d862e33015",
            "value": " 2/2 [00:04&lt;00:00,  2.21s/it]"
          }
        },
        "056f60c7ddaa43e09068d383f7b652bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "835c9939bfa3496cbe536b8e8bd5c392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c7019e07fbe4282b8356483e34e01ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d9b9dd87cb7403b90e0a7e630bf3ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65bc84768754465a9aff8bf017e7c8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "626c3eb81b4e4697b2ea217bf11735aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8259bdf307a46f38c70d3d862e33015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba0bc2a0f4694e40b80041e341d98c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1780f57865f94360a96d2b2f28e096f9",
              "IPY_MODEL_12995321365544cda86f34fc0c4a5af8",
              "IPY_MODEL_d7a83a48e8634521bafa93038e54fc62"
            ],
            "layout": "IPY_MODEL_94f6c2e3c49a442d97cdb042349e8a72"
          }
        },
        "1780f57865f94360a96d2b2f28e096f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d09dbbbe501d491fa5b67cbfa9528b7d",
            "placeholder": "​",
            "style": "IPY_MODEL_9e8cb17ce13c428584657b714ea3d323",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "12995321365544cda86f34fc0c4a5af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee3ff5bf9e5849b48960f396cf084ae5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49ac5b8e52464a0781f417ddfeb38524",
            "value": 2
          }
        },
        "d7a83a48e8634521bafa93038e54fc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_432f83d3f56149868fbda8d19a8272d8",
            "placeholder": "​",
            "style": "IPY_MODEL_04ff0b1dce964195a0b7da84b9ecfb5d",
            "value": " 2/2 [00:05&lt;00:00,  2.40s/it]"
          }
        },
        "94f6c2e3c49a442d97cdb042349e8a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d09dbbbe501d491fa5b67cbfa9528b7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e8cb17ce13c428584657b714ea3d323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee3ff5bf9e5849b48960f396cf084ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ac5b8e52464a0781f417ddfeb38524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "432f83d3f56149868fbda8d19a8272d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ff0b1dce964195a0b7da84b9ecfb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BKgp3cPfhNCE",
        "outputId": "f012e2e0-5604-4d1d-dc93-cf8d6277b16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: peft==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (4.46.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (0.26.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->peft==0.4.0) (0.26.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (0.20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (2024.8.30)\n",
            "Requirement already satisfied: bitsandbytes==0.41.3 in /usr/local/lib/python3.10/dist-packages (0.41.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: accelerate==0.26.0 in /usr/local/lib/python3.10/dist-packages (0.26.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.0) (0.26.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.0) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.26.0) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.26.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.26.0) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.26.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.26.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.26.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.26.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.26.0) (2024.8.30)\n",
            "Requirement already satisfied: trl==0.4.7 in /usr/local/lib/python3.10/dist-packages (0.4.7)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (4.46.3)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (1.26.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (0.26.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.4.7) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (0.20.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl==0.4.7) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (3.11.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.4.7) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.4.7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.4.7) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.4.7) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl==0.4.7) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.4.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.4.7) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.4.7) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.4.7) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers huggingface_hub\n",
        "!pip install peft==0.4.0\n",
        "!pip install bitsandbytes==0.41.3\n",
        "!pip install datasets\n",
        "!pip install wandb\n",
        "!pip install huggingface_hub\n",
        "!pip install accelerate==0.26.0\n",
        "!pip install trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import Dataset, load_dataset\n",
        "\n",
        "from transformers import(\n",
        "AutoTokenizer,\n",
        "AutoModelForCausalLM,\n",
        "TrainingArguments,\n",
        "Trainer\n",
        ")\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import bitsandbytes as bnb\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, default_data_collator\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, TaskType"
      ],
      "metadata": {
        "id": "Xvi55hv4jSjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"Dahoas/code-review-instruct-critique-revision-python\")\n",
        "dataset = dataset['train'] #.select(range(10))\n",
        "shuffled_dataset = dataset.shuffle(seed = 42)\n",
        "split_dataset = shuffled_dataset.train_test_split(test_size=0.2, seed = 42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7Y7Ems2joLB",
        "outputId": "6ef6e9f2-ea3f-4eb4-a3e8-5a95c4adf5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh9UgQghnYEw",
        "outputId": "62283018-7c71-45ad-9410-77448db1c6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['body', 'answer', 'comments', 'meta_data', 'question_id', 'prompt', 'response'],\n",
              "        num_rows: 7569\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['body', 'answer', 'comments', 'meta_data', 'question_id', 'prompt', 'response'],\n",
              "        num_rows: 1893\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "\n",
        "# Verify the sizes of the splits\n",
        "print(\"Train size:\", len(train_dataset))\n",
        "print(\"Test size:\", len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVvrV4BIlNU1",
        "outputId": "366f677c-4996-4dd3-f69f-5abbf88beac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 7569\n",
            "Test size: 1893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        ")\n",
        "\n",
        "# Load the model with 4-bit quantization\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-hf\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_fast = False)\n",
        "if not tokenizer.pad_token:\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token\n",
        "\n",
        "# Alternatively, add a custom padding token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))  # Resize embeddings if needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2762e86616214f2098e62e2a6c21db3c",
            "3925f284d4eb49a48a99dce362ccfef6",
            "cb4625bda1db4447bb39d11538f00775",
            "0a2a53ce84954e56919d7386848d45c0",
            "056f60c7ddaa43e09068d383f7b652bf",
            "835c9939bfa3496cbe536b8e8bd5c392",
            "9c7019e07fbe4282b8356483e34e01ea",
            "7d9b9dd87cb7403b90e0a7e630bf3ede",
            "65bc84768754465a9aff8bf017e7c8cb",
            "626c3eb81b4e4697b2ea217bf11735aa",
            "d8259bdf307a46f38c70d3d862e33015"
          ]
        },
        "id": "QoS2pUpblOwj",
        "outputId": "b2828a36-a48d-4beb-fc0e-17e636de0615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2762e86616214f2098e62e2a6c21db3c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example(example):\n",
        "    \"\"\"\n",
        "    Formats the dataset into a consistent structure using the given prompt and response.\n",
        "    \"\"\"\n",
        "    prompt = example.get('prompt', '').strip()\n",
        "    response = example.get('response', '').strip()\n",
        "\n",
        "    formatted_string = f\"\"\"\n",
        "    ### Task:\n",
        "    Analyze the provided problem and optimize the given Python code. Include constructive feedback and an improved version of the code.\n",
        "\n",
        "    ### Prompt:\n",
        "    {prompt}\n",
        "\n",
        "    ### Instructions:\n",
        "    1. Read and understand the original code and its problem statement.\n",
        "    2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
        "    3. Rewrite the code to address the critique.\n",
        "\n",
        "    ### Response:\n",
        "    {response}\n",
        "    \"\"\"\n",
        "\n",
        "    return formatted_string\n"
      ],
      "metadata": {
        "id": "QIoy9WSYnJJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(format_example(split_dataset[\"train\"][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3vuppGenQEx",
        "outputId": "79640fef-914d-47c5-ba05-ea41902456ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    ### Task:\n",
            "    Analyze the provided problem and optimize the given Python code. Include constructive feedback and an improved version of the code.\n",
            "\n",
            "    ### Prompt:\n",
            "    Question: <p>I wrote this script to add some config to a Juniper device.  It works well but the whole user input validation section (yes or no section) seems a little messy.</p>\n",
            "\n",
            "<p>Is there a better way I could have done it?</p>\n",
            "\n",
            "<pre><code>from jnpr.junos import Device\n",
            "from jnpr.junos.utils.config import Config\n",
            "import getpass\n",
            "\n",
            "#Grab credentials\n",
            "username = raw_input(\"Enter your username:\")\n",
            "password = getpass.getpass(\"Enter your password:\")\n",
            "\n",
            "#Confirmation of commands\n",
            "commands = open(\"commands\" , \"r\")\n",
            "commands_to_commit = commands.read()\n",
            "print \"\"\n",
            "print \"The commands you are about to commit are: \"\n",
            "print commands_to_commit\n",
            "print \"\"\n",
            "print \"Do you want to continue to run these commands?\"\n",
            "confirm = raw_input(\"Y or N: \")\n",
            "    if confirm in ['n','no','N','NO','No']:\n",
            "            print \"Exiting...\"\n",
            "            quit()\n",
            "while confirm not in ['y','Y','yes',\"Yes\",'YES','n','N','NO','No','no']:\n",
            "    print \"Invalid Choice, Try again\"\n",
            "    confirm = raw_input(\"Y or N: \")\n",
            "    if confirm in ['n','no','N','NO','No']:\n",
            "            print \"Exiting...\"\n",
            "            quit()\n",
            "    elif confirm in ['y','Y','yes',\"Yes\",'YES']:\n",
            "            continue\n",
            "\n",
            "#Open a file called swichlist which has a list of devices to modify\n",
            "with open('switchlist') as infile:\n",
            "    for host in infile:\n",
            "            try:\n",
            "                    print \"Working on:\", host,\n",
            "                    #Connect to devices in switchlist\n",
            "                    dev = Device(host=host.strip(),  user=username, password=password)\n",
            "                    dev.open()\n",
            "                    cu = Config(dev)\n",
            "                    #Looks for a file named commands with the list of commands to run\n",
            "                    incmd = open('commands')\n",
            "                    set_cmd = incmd.read()\n",
            "                    cu.load(set_cmd, format=\"set\")\n",
            "                    cu.commit()\n",
            "                    dev.close()\n",
            "                    print \"Completed:\", host\n",
            "            except Exception,e: print \"Error:\", e\n",
            "            continue\n",
            "</code></pre>\n",
            " \n",
            "\n",
            " Answer: <p>You can get rid of the first: </p>\n",
            "\n",
            "<pre><code>confirm = raw_input(\"Y or N: \").lower()\n",
            "if confirm in ['n', 'no']:\n",
            "    print \"Exiting...\"\n",
            "    quit()\n",
            "</code></pre>\n",
            "\n",
            "<p>right off the bat. Just initialize <code>confirm</code> to <code>''</code>and it'll kick you into the <code>while</code> loop. </p>\n",
            "\n",
            "<p>You can also move the <code>'switchlist'</code> and <code>'commands'</code> filenames to variables so they aren't hard coded. Ideally, you should move them to a config file or cli args. </p>\n",
            "\n",
            "<p>Below is the updated/cleaned up version of your code:</p>\n",
            "\n",
            "<pre><code>from jnpr.junos import Device\n",
            "from jnpr.junos.utils.config import Config\n",
            "import getpass\n",
            "\n",
            "commands_filename = 'commands'\n",
            "switchlist_filename = 'switchlist'\n",
            "\n",
            "# Grab credentials\n",
            "username = raw_input('Enter your username:')\n",
            "password = getpass.getpass('Enter your password:')\n",
            "\n",
            "# Confirmation of commands\n",
            "commands_to_commit = open(commands_filename, 'r').read()\n",
            "\n",
            "print ''\n",
            "print 'The commands you are about to commit are: '\n",
            "print commands_to_commit\n",
            "print ''\n",
            "print 'Do you want to continue to run these commands?'\n",
            "\n",
            "confirm = ''\n",
            "while confirm not in ['y', 'ye', 'yes', 'n', 'no']:\n",
            "    confirm = raw_input('Y or N: ').lower()\n",
            "    if confirm in ['n', 'no']:\n",
            "        print 'Exiting...'\n",
            "        quit()\n",
            "    elif confirm in ['y', 'ye', 'yes']:\n",
            "        continue\n",
            "    else:\n",
            "        print 'Invalid choice, try again'\n",
            "\n",
            "# Open a file called swichlist which has a list of devices to modify\n",
            "with open(switchlist_filename) as infile:\n",
            "    for host in infile:\n",
            "        try:\n",
            "            print 'Working on: ', host\n",
            "\n",
            "            # Connect to devices in switchlist\n",
            "            dev = Device(host=host.strip(),  user=username, password=password)\n",
            "            dev.open()\n",
            "            cu = Config(dev)\n",
            "\n",
            "            # Looks for a file named commands with the list of commands to run\n",
            "            set_cmd = open(commands_filename).read()\n",
            "            cu.load(set_cmd, format='set')\n",
            "            cu.commit()\n",
            "            dev.close()\n",
            "\n",
            "            print 'Completed: ', host\n",
            "        except Exception,e: \n",
            "            print 'Exception: ', str(e)\n",
            "            continue\n",
            "</code></pre>\n",
            " \n",
            "\n",
            " This is a question and answer from a forum where users review and improve the code of other users. Please output the original code, a summary of the critique, and the revised code using the format ORIGINAL: [write original code here] CRITIQUE: [write critique here] REVISED: [write revision code here].\n",
            "\n",
            "    ### Instructions:\n",
            "    1. Read and understand the original code and its problem statement.\n",
            "    2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
            "    3. Rewrite the code to address the critique.\n",
            "\n",
            "    ### Response:\n",
            "    ORIGINAL: \n",
            "from jnpr.junos import Device\n",
            "from jnpr.junos.utils.config import Config\n",
            "import getpass\n",
            "\n",
            "#Grab credentials\n",
            "username = raw_input(\"Enter your username:\")\n",
            "password = getpass.getpass(\"Enter your password:\")\n",
            "\n",
            "#Confirmation of commands\n",
            "commands = open(\"commands\" , \"r\")\n",
            "commands_to_commit = commands.read()\n",
            "print \"\"\n",
            "print \"The commands you are about to commit are: \"\n",
            "print commands_to_commit\n",
            "print \"\"\n",
            "print \"Do you want to continue to run these commands?\"\n",
            "confirm = raw_input(\"Y or N: \")\n",
            "    if confirm in ['n','no','N','NO','No']:\n",
            "            print \"Exiting...\"\n",
            "            quit()\n",
            "while confirm not in ['y','Y','yes',\"Yes\",'YES','n','N','NO','No','no']:\n",
            "    print \"Invalid Choice, Try again\"\n",
            "    confirm = raw_input(\"Y or N: \")\n",
            "    if confirm in ['n','no','N','NO','No']:\n",
            "            print \"Exiting...\"\n",
            "            quit()\n",
            "    elif confirm in ['y','Y','yes',\"Yes\",'YES']:\n",
            "            continue\n",
            "\n",
            "#Open a file called swichlist which has a list of devices to modify\n",
            "with open('switchlist') as infile:\n",
            "    for host in infile:\n",
            "            try:\n",
            "                    print \"Working on:\", host,\n",
            "                    #Connect to devices in switchlist\n",
            "                    dev = Device(host=host.strip(),  user=username, password=password)\n",
            "                    dev.open()\n",
            "                    cu = Config(dev)\n",
            "                    #Looks for a file named commands with the list of commands to run\n",
            "                    incmd = open('commands')\n",
            "                    set_cmd = incmd.read()\n",
            "                    cu.load(set_cmd, format=\"set\")\n",
            "                    cu.commit()\n",
            "                    dev.close()\n",
            "                    print \"Completed:\", host\n",
            "            except Exception,e: print \"Error:\", e\n",
            "            continue\n",
            "\n",
            "CRITIQUE: \n",
            "The user input validation section can be improved by getting rid of the first confirmation and initializing confirm to an empty string. Additionally, the 'switchlist' and 'commands' filenames should be moved to variables so they aren't hard coded.\n",
            "\n",
            "REVISED: \n",
            "from jnpr.junos import Device\n",
            "from jnpr.junos.utils.config import Config\n",
            "import getpass\n",
            "\n",
            "commands_filename = 'commands'\n",
            "switchlist_filename = 'switchlist'\n",
            "\n",
            "# Grab credentials\n",
            "username = raw_input('Enter your username:')\n",
            "password = getpass.getpass('Enter your password:')\n",
            "\n",
            "# Confirmation of commands\n",
            "commands_to_commit = open(commands_filename, 'r').read()\n",
            "\n",
            "print ''\n",
            "print 'The commands you are about to commit are: '\n",
            "print commands_to_commit\n",
            "print ''\n",
            "print 'Do you want to continue to run these commands?'\n",
            "\n",
            "confirm = ''\n",
            "while confirm not in ['y', 'ye', 'yes', 'n', 'no']:\n",
            "    confirm = raw_input('Y or N: ').lower()\n",
            "    if confirm in ['n', 'no']:\n",
            "        print 'Exiting...'\n",
            "        quit()\n",
            "    elif confirm in ['y', 'ye', 'yes']:\n",
            "        continue\n",
            "    else:\n",
            "        print 'Invalid choice, try again'\n",
            "\n",
            "# Open a file called swichlist which has a list of devices to modify\n",
            "with open(switchlist_filename) as infile:\n",
            "    for host in infile:\n",
            "        try:\n",
            "            print 'Working on: ', host\n",
            "\n",
            "            # Connect to devices in switchlist\n",
            "            dev = Device(host=host.strip(),  user=username, password=password)\n",
            "            dev.open()\n",
            "            cu = Config(dev)\n",
            "\n",
            "            # Looks for a file named commands with the list of commands to run\n",
            "            set_cmd = open(commands_filename).read()\n",
            "            cu.load(set_cmd, format='set')\n",
            "            cu.commit()\n",
            "            dev.close()\n",
            "\n",
            "            print 'Completed: ', host\n",
            "        except Exception,e: \n",
            "            print 'Exception: ', str(e)\n",
            "            continue\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    \"\"\"\n",
        "    Tokenize the formatted examples from the dataset for the given structure.\n",
        "    \"\"\"\n",
        "    # Create formatted strings for the batch\n",
        "    formatted_examples = [\n",
        "        format_example({\n",
        "            'prompt': prompt,\n",
        "            'response': response,\n",
        "        })\n",
        "        for prompt, response in zip(\n",
        "            examples['prompt'],\n",
        "            examples['response'],\n",
        "        )\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Tokenize the formatted examples\n",
        "    tokenized = tokenizer(\n",
        "        formatted_examples,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "    )\n",
        "\n",
        "    # Set the labels\n",
        "    tokenized['labels'] = tokenized['input_ids'].copy()\n",
        "    return tokenized\n"
      ],
      "metadata": {
        "id": "cA6hVSP3nc9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the final zero-shot prompt\n",
        "zero_shot_prompt = \"\"\"\n",
        "### Task:\n",
        "Analyze the provided problem and optimize the given Python code. Provide constructive feedback and generate an improved version of the code.\n",
        "\n",
        "### Prompt:\n",
        "<p>I'd like suggestions for optimizing this brute force solution to <a href=\"http://projecteuler.net/index.php?section=problems&amp;id=1\">problem 1</a>. The algorithm currently checks every integer between 3 and 1000. I'd like to cut as many unnecessary calls to <code>isMultiple</code> as possible:</p>\n",
        "<pre><code>'''\n",
        "If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9. The sum of these multiples is 23. Find the sum of all the multiples of 3 or 5 below 1000.\n",
        "'''\n",
        "end = 1000\n",
        "\n",
        "def Solution01():\n",
        "    ''' Solved by brute force #OPTIMIZE '''\n",
        "    sum = 0\n",
        "    for i in range(3, end):\n",
        "        if isMultiple(i):\n",
        "            sum += i\n",
        "    print(sum)\n",
        "\n",
        "def isMultiple(i):\n",
        "    return (i % 3 == 0) or (i % 5 == 0)\n",
        "</code></pre>\n",
        "\n",
        "### Instructions:\n",
        "1. Read and understand the original code and its problem statement.\n",
        "2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
        "3. Rewrite the code to address the critique.\n",
        "4. Begin your critique with \"Critique:\" and your revised code with \"Revised Code:\".\n",
        "\n",
        "##Response:\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "475KInfyq_uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = zero_shot_prompt\n",
        "input_ids = tokenizer(final_prompt, return_tensors=\"pt\").input_ids\n",
        "output = model.generate( input_ids, max_length=1024, temperature=0.7, top_p=0.95, repetition_penalty=1.2, num_return_sequences=1, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TENlwYwOrH3p",
        "outputId": "d84e14cc-46c5-4d93-e0e7-c897d38122e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VswPeqBHrKuM",
        "outputId": "865ad6f6-3224-4332-fec8-9a8b6df0a6b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Task:\n",
            "Analyze the provided problem and optimize the given Python code. Provide constructive feedback and generate an improved version of the code.\n",
            "\n",
            "### Prompt:\n",
            "<p>I'd like suggestions for optimizing this brute force solution to <a href=\"http://projecteuler.net/index.php?section=problems&amp;id=1\">problem 1</a>. The algorithm currently checks every integer between 3 and 1000. I'd like to cut as many unnecessary calls to <code>isMultiple</code> as possible:</p>\n",
            "<pre><code>'''\n",
            "If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9. The sum of these multiples is 23. Find the sum of all the multiples of 3 or 5 below 1000.\n",
            "'''\n",
            "end = 1000\n",
            "\n",
            "def Solution01():\n",
            "    ''' Solved by brute force #OPTIMIZE '''\n",
            "    sum = 0\n",
            "    for i in range(3, end):\n",
            "        if isMultiple(i):\n",
            "            sum += i\n",
            "    print(sum)\n",
            "\n",
            "def isMultiple(i):\n",
            "    return (i % 3 == 0) or (i % 5 == 0)\n",
            "</code></pre>\n",
            "\n",
            "### Instructions:\n",
            "1. Read and understand the original code and its problem statement.\n",
            "2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
            "3. Rewrite the code to address the critique.\n",
            "4. Begin your critique with \"Critique:\" and your revised code with \"Revised Code:\".\n",
            "\n",
            "##Response:\n",
            "\n",
            "```python\n",
            "class Solution01:\n",
            "\t\"\"\" Solved by brute force \"\"\"\n",
            "\tdef __init__(self, end):\n",
            "\t\tif not type(end)==int:\n",
            "\t\t\traise TypeError('TypeError : end must be int')\n",
            "\t\telse:\n",
            "\t\t\tself.__range_start__=-end\n",
            "\t\t\tself.__range_end__=(end-1)+1\n",
            "\tdef isMultiple(self, x):\n",
            "\t\treturn self.__checkx_modulo(x%3,x%5)==[True]or[False],self.__checky_modulo([])+=[True]+self.__checkz_modulo([])\n",
            "\t@staticmethod\n",
            "\tdef checkx_modulo(x,list,y,z):\n",
            "\t\tif x!=0:\n",
            "\t\t\twhile y[-1]:\n",
            "\t\t\t\tif z:-1<=x>=0:\n",
            "\t\t\t\t\tfor n in xrange(*y+1,-1)[::-1][1:]*10**len(y)*self._powers:\n",
            "\t\t\t\t\t\tif n!=0:\n",
            "\t\t\t\t\t\t\tbreak\n",
            "\t\t\t\t\t\telif y[-1]=[]: break\n",
            "\t\t\t\t\t\telse: y[-1].append(-n); continue\n",
            "\t\t\t\t\tif self._get_bool(x,list,y,z)==True:\n",
            "\t\t\t\t\t\tif x not in [y[-1]]:#add -1 only once per while loop\n",
            "\t\t\t\t\t\t\ty.pop()\n",
            "\t\t\t\t\t\t\tz.remove((-x))\n",
            "\t\t\t\t\t\t\tl=[]\n",
            "\t\t\t\t\t\t\tfor f in l[:]*10**len(l)-1:f+=1\n",
            "\t\t\t\t\t\t\twhile True:\n",
            "\t\t\t\t\t\t\t\tif l:l[-1]=f+(l[0]>>1),l=[f]+l[1:];continue\n",
            "\t\t\t\t\t\t\t\telif len(y)>0:l=[1](*y)+z,(*l[1:]).sort(),l=[self._powers[l[0]],l[1]];continue\n",
            "\t\t\t\t\t\t\t\telse: break\n",
            "\t\t\t\t\t\t\t\telse: pass\n",
            "\t\t\t\t\t\t\tl.reverse();print(''.join(str(m)))\n",
            "\t\t\t\t\t\t\tbreak\n",
            "\t\t\t\t\t\telse: pass\n",
            "\t\t\t\t\telse: pass\n",
            "\t\t\t\t\ty[-1].append(n)\n",
            "\t\t\t\t\tif y[-1]==0:y.clear()\n",
            "\t\t\t\telse:\n",
            "\t\t\t\t\tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = \"\"\"\n",
        "### Task:\n",
        "Analyze the provided problem and optimize the given code. Provide constructive feedback and generate an improved version of the code.\n",
        "\n",
        "### Prompt:\n",
        "<p>I'd like suggestions for optimizing this brute force solution to <a href=\"http://projecteuler.net/index.php?section=problems&amp;id=1\">problem 1</a>. The algorithm currently checks every integer between 3 and 1000. I'd like to cut as many unnecessary calls to <code>isMultiple</code> as possible:</p>\n",
        "<pre><code>'''\n",
        "If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9. The sum of these multiples is 23. Find the sum of all the multiples of 3 or 5 below 1000.\n",
        "'''\n",
        "end = 1000\n",
        "\n",
        "def Solution01():\n",
        "    ''' Solved by brute force #OPTIMIZE '''\n",
        "    sum = 0\n",
        "    for i in range(3, end):\n",
        "        if isMultiple(i):\n",
        "            sum += i\n",
        "    print(sum)\n",
        "\n",
        "def isMultiple(i):\n",
        "    return (i % 3 == 0) or (i % 5 == 0)\n",
        "</code></pre>\n",
        "\n",
        "### Instructions:\n",
        "1. Read and understand the original code and its problem statement.\n",
        "2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
        "3. Rewrite the code to address the critique.\n",
        "4. Begin your critique with \"Critique:\" and your revised code with \"Revised Code:\".\n",
        "\n",
        "### Response:\n",
        "\n",
        "### Critique:\n",
        "The algorithm currently checks every integer between 3 and 1000, making unnecessary calls to `isMultiple`, which is inefficient. Instead, we can iterate over multiples of 3 and 5 directly, avoiding repeated checks.\n",
        "\n",
        "### Revised Code:\n",
        "```python\n",
        "end = 1000\n",
        "total = 0\n",
        "for i in range(3, end, 3):\n",
        "    total += i\n",
        "for i in range(5, end, 5):\n",
        "    if i % 3 != 0:\n",
        "        total += i\n",
        "print(total)\"\"\"\n",
        "\n",
        "new_question = \"\"\"\n",
        "### Task:\n",
        "Analyze the provided problem and optimize the given code. Provide constructive feedback and generate an improved version of the code.\n",
        "\n",
        "### Prompt:\n",
        "I have written a function that calculates the factorial of a number recursively. However, the code is not optimized for larger inputs as it can cause a stack overflow. I would like suggestions on optimizing this code:\n",
        "\n",
        "function factorial(n) {\n",
        "    if (n === 0 || n === 1) {\n",
        "        return 1;\n",
        "    }\n",
        "    return n * factorial(n - 1);\n",
        "}\n",
        "\n",
        "console.log(factorial(5));\n",
        "\n",
        "### Instructions:\n",
        "1. Read and understand the original code and its problem statement.\n",
        "2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
        "3. Rewrite the code to address the critique.\n",
        "4. Begin your critique with \"Critique:\" and your revised code with \"Revised Code:\".\n",
        "\n",
        "### Response:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-D7UOPNArjwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = few_shot_prompt + new_question\n",
        "input_ids = tokenizer(final_prompt, return_tensors=\"pt\").input_ids\n",
        "output = model.generate( input_ids, max_length=1024, temperature=0.7, top_p=0.95, repetition_penalty=1.2, num_return_sequences=1, )"
      ],
      "metadata": {
        "id": "47-2jP2MrpwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhLH0vylrv3_",
        "outputId": "36e72d71-9179-40a3-ceb5-3dab5ea45ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Task:\n",
            "Analyze the provided problem and optimize the given code. Provide constructive feedback and generate an improved version of the code.\n",
            "\n",
            "### Prompt:\n",
            "<p>I'd like suggestions for optimizing this brute force solution to <a href=\"http://projecteuler.net/index.php?section=problems&amp;id=1\">problem 1</a>. The algorithm currently checks every integer between 3 and 1000. I'd like to cut as many unnecessary calls to <code>isMultiple</code> as possible:</p>\n",
            "<pre><code>'''\n",
            "If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9. The sum of these multiples is 23. Find the sum of all the multiples of 3 or 5 below 1000.\n",
            "'''\n",
            "end = 1000\n",
            "\n",
            "def Solution01():\n",
            "    ''' Solved by brute force #OPTIMIZE '''\n",
            "    sum = 0\n",
            "    for i in range(3, end):\n",
            "        if isMultiple(i):\n",
            "            sum += i\n",
            "    print(sum)\n",
            "\n",
            "def isMultiple(i):\n",
            "    return (i % 3 == 0) or (i % 5 == 0)\n",
            "</code></pre>\n",
            "\n",
            "### Instructions:\n",
            "1. Read and understand the original code and its problem statement.\n",
            "2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
            "3. Rewrite the code to address the critique.\n",
            "4. Begin your critique with \"Critique:\" and your revised code with \"Revised Code:\".\n",
            "\n",
            "### Response:\n",
            "\n",
            "### Critique:\n",
            "The algorithm currently checks every integer between 3 and 1000, making unnecessary calls to `isMultiple`, which is inefficient. Instead, we can iterate over multiples of 3 and 5 directly, avoiding repeated checks.\n",
            "\n",
            "### Revised Code:\n",
            "```python\n",
            "end = 1000\n",
            "total = 0\n",
            "for i in range(3, end, 3):\n",
            "    total += i\n",
            "for i in range(5, end, 5):\n",
            "    if i % 3 != 0:\n",
            "        total += i\n",
            "print(total)\n",
            "### Task:\n",
            "Analyze the provided problem and optimize the given code. Provide constructive feedback and generate an improved version of the code.\n",
            "\n",
            "### Prompt:\n",
            "I have written a function that calculates the factorial of a number recursively. However, the code is not optimized for larger inputs as it can cause a stack overflow. I would like suggestions on optimizing this code:\n",
            "\n",
            "function factorial(n) {\n",
            "    if (n === 0 || n === 1) {\n",
            "        return 1;\n",
            "    }\n",
            "    return n * factorial(n - 1);\n",
            "}\n",
            "\n",
            "console.log(factorial(5));\n",
            "\n",
            "### Instructions:\n",
            "1. Read and understand the original code and its problem statement.\n",
            "2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
            "3. Rewrite the code to address the critique.\n",
            "4. Begin your critique with \"Critique:\" and your revised code with \"Revised Code:\".\n",
            "\n",
            "### Response:\n",
            "\n",
            "### Critique:\n",
            "The recursive implementation will result in a stack overflow when inputting values greater than 8 because the function call stack grows exponentially based on recursion depth. You could replace the recursion with iterative logic such as the following:\n",
            "\n",
            "`factorial_iteration`:\n",
            "\n",
            "```javascript\n",
            "function factorial_iteration(num){\n",
            "\tif (num <= 1) return num; // base case -- no need to recurse\n",
            "\n",
            "\tlet prevFactorialResult = 1;\n",
            "\n",
            "\t// Recursive case (too deep though!)\n",
            "\treturn prevFactorialResult*prevFactorialResult;\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify columns to retain\n",
        "columns_to_keep = ['prompt', 'response']\n",
        "\n",
        "# Remove unnecessary columns dynamically\n",
        "columns_to_remove_train = [col for col in train_dataset.column_names if col not in columns_to_keep]\n",
        "columns_to_remove_test = [col for col in test_dataset.column_names if col not in columns_to_keep]\n",
        "\n",
        "# Tokenize train dataset\n",
        "train_dataset = train_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=columns_to_remove_train,\n",
        ")\n",
        "\n",
        "# Tokenize test dataset\n",
        "test_dataset = test_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=columns_to_remove_test,\n",
        ")\n",
        "\n",
        "# Verify tokenized datasets\n",
        "print(\"Tokenized Train Dataset Sample:\", train_dataset[0])\n",
        "print(\"Tokenized Test Dataset Sample:\", test_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1xCkCGFr8FT",
        "outputId": "72802d41-23c2-46e1-d757-cc82ded48c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Train Dataset Sample: {'prompt': 'Question: <p>I wrote this script to add some config to a Juniper device.  It works well but the whole user input validation section (yes or no section) seems a little messy.</p>\\n\\n<p>Is there a better way I could have done it?</p>\\n\\n<pre><code>from jnpr.junos import Device\\nfrom jnpr.junos.utils.config import Config\\nimport getpass\\n\\n#Grab credentials\\nusername = raw_input(\"Enter your username:\")\\npassword = getpass.getpass(\"Enter your password:\")\\n\\n#Confirmation of commands\\ncommands = open(\"commands\" , \"r\")\\ncommands_to_commit = commands.read()\\nprint \"\"\\nprint \"The commands you are about to commit are: \"\\nprint commands_to_commit\\nprint \"\"\\nprint \"Do you want to continue to run these commands?\"\\nconfirm = raw_input(\"Y or N: \")\\n    if confirm in [\\'n\\',\\'no\\',\\'N\\',\\'NO\\',\\'No\\']:\\n            print \"Exiting...\"\\n            quit()\\nwhile confirm not in [\\'y\\',\\'Y\\',\\'yes\\',\"Yes\",\\'YES\\',\\'n\\',\\'N\\',\\'NO\\',\\'No\\',\\'no\\']:\\n    print \"Invalid Choice, Try again\"\\n    confirm = raw_input(\"Y or N: \")\\n    if confirm in [\\'n\\',\\'no\\',\\'N\\',\\'NO\\',\\'No\\']:\\n            print \"Exiting...\"\\n            quit()\\n    elif confirm in [\\'y\\',\\'Y\\',\\'yes\\',\"Yes\",\\'YES\\']:\\n            continue\\n\\n#Open a file called swichlist which has a list of devices to modify\\nwith open(\\'switchlist\\') as infile:\\n    for host in infile:\\n            try:\\n                    print \"Working on:\", host,\\n                    #Connect to devices in switchlist\\n                    dev = Device(host=host.strip(),  user=username, password=password)\\n                    dev.open()\\n                    cu = Config(dev)\\n                    #Looks for a file named commands with the list of commands to run\\n                    incmd = open(\\'commands\\')\\n                    set_cmd = incmd.read()\\n                    cu.load(set_cmd, format=\"set\")\\n                    cu.commit()\\n                    dev.close()\\n                    print \"Completed:\", host\\n            except Exception,e: print \"Error:\", e\\n            continue\\n</code></pre>\\n \\n\\n Answer: <p>You can get rid of the first: </p>\\n\\n<pre><code>confirm = raw_input(\"Y or N: \").lower()\\nif confirm in [\\'n\\', \\'no\\']:\\n    print \"Exiting...\"\\n    quit()\\n</code></pre>\\n\\n<p>right off the bat. Just initialize <code>confirm</code> to <code>\\'\\'</code>and it\\'ll kick you into the <code>while</code> loop. </p>\\n\\n<p>You can also move the <code>\\'switchlist\\'</code> and <code>\\'commands\\'</code> filenames to variables so they aren\\'t hard coded. Ideally, you should move them to a config file or cli args. </p>\\n\\n<p>Below is the updated/cleaned up version of your code:</p>\\n\\n<pre><code>from jnpr.junos import Device\\nfrom jnpr.junos.utils.config import Config\\nimport getpass\\n\\ncommands_filename = \\'commands\\'\\nswitchlist_filename = \\'switchlist\\'\\n\\n# Grab credentials\\nusername = raw_input(\\'Enter your username:\\')\\npassword = getpass.getpass(\\'Enter your password:\\')\\n\\n# Confirmation of commands\\ncommands_to_commit = open(commands_filename, \\'r\\').read()\\n\\nprint \\'\\'\\nprint \\'The commands you are about to commit are: \\'\\nprint commands_to_commit\\nprint \\'\\'\\nprint \\'Do you want to continue to run these commands?\\'\\n\\nconfirm = \\'\\'\\nwhile confirm not in [\\'y\\', \\'ye\\', \\'yes\\', \\'n\\', \\'no\\']:\\n    confirm = raw_input(\\'Y or N: \\').lower()\\n    if confirm in [\\'n\\', \\'no\\']:\\n        print \\'Exiting...\\'\\n        quit()\\n    elif confirm in [\\'y\\', \\'ye\\', \\'yes\\']:\\n        continue\\n    else:\\n        print \\'Invalid choice, try again\\'\\n\\n# Open a file called swichlist which has a list of devices to modify\\nwith open(switchlist_filename) as infile:\\n    for host in infile:\\n        try:\\n            print \\'Working on: \\', host\\n\\n            # Connect to devices in switchlist\\n            dev = Device(host=host.strip(),  user=username, password=password)\\n            dev.open()\\n            cu = Config(dev)\\n\\n            # Looks for a file named commands with the list of commands to run\\n            set_cmd = open(commands_filename).read()\\n            cu.load(set_cmd, format=\\'set\\')\\n            cu.commit()\\n            dev.close()\\n\\n            print \\'Completed: \\', host\\n        except Exception,e: \\n            print \\'Exception: \\', str(e)\\n            continue\\n</code></pre>\\n \\n\\n This is a question and answer from a forum where users review and improve the code of other users. Please output the original code, a summary of the critique, and the revised code using the format ORIGINAL: [write original code here] CRITIQUE: [write critique here] REVISED: [write revision code here]. \\n\\n', 'response': ' ORIGINAL: \\nfrom jnpr.junos import Device\\nfrom jnpr.junos.utils.config import Config\\nimport getpass\\n\\n#Grab credentials\\nusername = raw_input(\"Enter your username:\")\\npassword = getpass.getpass(\"Enter your password:\")\\n\\n#Confirmation of commands\\ncommands = open(\"commands\" , \"r\")\\ncommands_to_commit = commands.read()\\nprint \"\"\\nprint \"The commands you are about to commit are: \"\\nprint commands_to_commit\\nprint \"\"\\nprint \"Do you want to continue to run these commands?\"\\nconfirm = raw_input(\"Y or N: \")\\n    if confirm in [\\'n\\',\\'no\\',\\'N\\',\\'NO\\',\\'No\\']:\\n            print \"Exiting...\"\\n            quit()\\nwhile confirm not in [\\'y\\',\\'Y\\',\\'yes\\',\"Yes\",\\'YES\\',\\'n\\',\\'N\\',\\'NO\\',\\'No\\',\\'no\\']:\\n    print \"Invalid Choice, Try again\"\\n    confirm = raw_input(\"Y or N: \")\\n    if confirm in [\\'n\\',\\'no\\',\\'N\\',\\'NO\\',\\'No\\']:\\n            print \"Exiting...\"\\n            quit()\\n    elif confirm in [\\'y\\',\\'Y\\',\\'yes\\',\"Yes\",\\'YES\\']:\\n            continue\\n\\n#Open a file called swichlist which has a list of devices to modify\\nwith open(\\'switchlist\\') as infile:\\n    for host in infile:\\n            try:\\n                    print \"Working on:\", host,\\n                    #Connect to devices in switchlist\\n                    dev = Device(host=host.strip(),  user=username, password=password)\\n                    dev.open()\\n                    cu = Config(dev)\\n                    #Looks for a file named commands with the list of commands to run\\n                    incmd = open(\\'commands\\')\\n                    set_cmd = incmd.read()\\n                    cu.load(set_cmd, format=\"set\")\\n                    cu.commit()\\n                    dev.close()\\n                    print \"Completed:\", host\\n            except Exception,e: print \"Error:\", e\\n            continue\\n\\nCRITIQUE: \\nThe user input validation section can be improved by getting rid of the first confirmation and initializing confirm to an empty string. Additionally, the \\'switchlist\\' and \\'commands\\' filenames should be moved to variables so they aren\\'t hard coded.\\n\\nREVISED: \\nfrom jnpr.junos import Device\\nfrom jnpr.junos.utils.config import Config\\nimport getpass\\n\\ncommands_filename = \\'commands\\'\\nswitchlist_filename = \\'switchlist\\'\\n\\n# Grab credentials\\nusername = raw_input(\\'Enter your username:\\')\\npassword = getpass.getpass(\\'Enter your password:\\')\\n\\n# Confirmation of commands\\ncommands_to_commit = open(commands_filename, \\'r\\').read()\\n\\nprint \\'\\'\\nprint \\'The commands you are about to commit are: \\'\\nprint commands_to_commit\\nprint \\'\\'\\nprint \\'Do you want to continue to run these commands?\\'\\n\\nconfirm = \\'\\'\\nwhile confirm not in [\\'y\\', \\'ye\\', \\'yes\\', \\'n\\', \\'no\\']:\\n    confirm = raw_input(\\'Y or N: \\').lower()\\n    if confirm in [\\'n\\', \\'no\\']:\\n        print \\'Exiting...\\'\\n        quit()\\n    elif confirm in [\\'y\\', \\'ye\\', \\'yes\\']:\\n        continue\\n    else:\\n        print \\'Invalid choice, try again\\'\\n\\n# Open a file called swichlist which has a list of devices to modify\\nwith open(switchlist_filename) as infile:\\n    for host in infile:\\n        try:\\n            print \\'Working on: \\', host\\n\\n            # Connect to devices in switchlist\\n            dev = Device(host=host.strip(),  user=username, password=password)\\n            dev.open()\\n            cu = Config(dev)\\n\\n            # Looks for a file named commands with the list of commands to run\\n            set_cmd = open(commands_filename).read()\\n            cu.load(set_cmd, format=\\'set\\')\\n            cu.commit()\\n            dev.close()\\n\\n            print \\'Completed: \\', host\\n        except Exception,e: \\n            print \\'Exception: \\', str(e)\\n            continue', 'input_ids': [1, 29871, 13, 1678, 835, 9330, 29901, 13, 1678, 11597, 29891, 911, 278, 4944, 1108, 322, 24656, 278, 2183, 5132, 775, 29889, 512, 2325, 3386, 573, 16705, 322, 385, 16710, 1873, 310, 278, 775, 29889, 13, 13, 1678, 835, 9705, 415, 29901, 13, 1678, 894, 29901, 529, 29886, 29958, 29902, 5456, 445, 2471, 304, 788, 777, 2295, 304, 263, 7452, 546, 4742, 29889, 29871, 739, 1736, 1532, 541, 278, 3353, 1404, 1881, 8845, 4004, 313, 3582, 470, 694, 4004, 29897, 2444, 263, 2217, 4473, 29891, 21106, 29886, 29958, 13, 13, 29966, 29886, 29958, 3624, 727, 263, 2253, 982, 306, 1033, 505, 2309, 372, 29973, 829, 29886, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 3166, 432, 29876, 558, 29889, 29926, 12609, 1053, 21830, 13, 3166, 432, 29876, 558, 29889, 29926, 12609, 29889, 13239, 29889, 2917, 1053, 12782, 13, 5215, 679, 3364, 13, 13, 29937, 29954, 4201, 16140, 13, 6786, 353, 10650, 29918, 2080, 703, 10399, 596, 8952, 29901, 1159, 13, 5630, 353, 679, 3364, 29889, 657, 3364, 703, 10399, 596, 4800, 29901, 1159, 13, 13, 29937, 16376, 3568, 362, 310, 8260, 13, 26381, 353, 1722, 703, 26381, 29908, 1919, 376, 29878, 1159, 13, 26381, 29918, 517, 29918, 15060, 353, 8260, 29889, 949, 580, 13, 2158, 5124, 13, 2158, 376, 1576, 8260, 366, 526, 1048, 304, 9063, 526, 29901, 376, 13, 2158, 8260, 29918, 517, 29918, 15060, 13, 2158, 5124, 13, 2158, 376, 6132, 366, 864, 304, 6773, 304, 1065, 1438, 8260, 3026, 13, 26897, 353, 10650, 29918, 2080, 703, 29979, 470, 405, 29901, 16521, 13, 1678, 565, 9659, 297, 6024, 29876, 3788, 1217, 3788, 29940, 3788, 6632, 3788, 3782, 2033, 29901, 13, 9651, 1596, 376, 1252, 11407, 17794, 13, 9651, 23283, 580, 13, 8000, 9659, 451, 297, 6024, 29891, 3788, 29979, 3788, 3582, 742, 29908, 8241, 613, 29915, 21143, 3788, 29876, 3788, 29940, 3788, 6632, 3788, 3782, 3788, 1217, 2033, 29901, 13, 1678, 1596, 376, 13919, 14542, 625, 29892, 3967, 1449, 29908, 13, 1678, 9659, 353, 10650, 29918, 2080, 703, 29979, 470, 405, 29901, 16521, 13, 1678, 565, 9659, 297, 6024, 29876, 3788, 1217, 3788, 29940, 3788, 6632, 3788, 3782, 2033, 29901, 13, 9651, 1596, 376, 1252, 11407, 17794, 13, 9651, 23283, 580, 13, 1678, 25342, 9659, 297, 6024, 29891, 3788, 29979, 3788, 3582, 742, 29908, 8241, 613, 29915, 21143, 2033, 29901, 13, 9651, 6773, 13, 13, 29937, 6585, 263, 934, 2000, 2381, 436, 1761, 607, 756, 263, 1051, 310, 9224, 304, 6623, 13, 2541, 1722, 877, 15123, 1761, 1495, 408, 297, 1445, 29901, 13, 1678, 363, 3495, 297, 297, 1445, 29901, 13, 9651, 1018, 29901, 13, 462, 1678, 1596, 376, 5531, 292, 373, 29901, 613, 3495, 29892, 13, 462, 1678, 396, 17918, 304, 9224, 297, 4607, 1761, 13, 462, 1678, 2906, 353, 21830, 29898, 3069, 29922, 3069, 29889, 17010, 3285, 29871, 1404, 29922, 6786, 29892, 4800, 29922, 5630, 29897, 13, 462, 1678, 2906, 29889, 3150, 580, 13, 462, 1678, 2723, 353, 12782, 29898, 3359, 29897, 13, 462, 1678, 396, 14959, 29879, 363, 263, 934, 4257, 8260, 411, 278, 1051, 310, 8260, 304, 1065, 13, 462, 1678, 5528, 3487, 353, 1722, 877, 26381, 1495, 13, 462, 1678, 731, 29918, 9006, 353, 5528, 3487, 29889, 949, 580, 13, 462, 1678, 2723, 29889, 1359, 29898, 842, 29918, 9006, 29892, 3402, 543, 842, 1159, 13, 462, 1678, 2723, 29889, 15060, 580, 13, 462, 1678, 2906, 29889, 5358, 580, 13, 462, 1678, 1596, 376, 26010, 29901, 613, 3495, 13, 9651, 5174, 8960, 29892, 29872, 29901, 1596, 376, 2392, 29901, 613, 321, 13, 9651, 6773, 13, 829, 401, 2565, 1457, 29958, 13, 29871, 13, 13, 673, 29901, 529, 29886, 29958, 3492, 508, 679, 8177, 310, 278, 937, 29901, 1533, 29886, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 26897, 353, 10650, 29918, 2080, 703, 29979, 470, 405, 29901, 376, 467, 13609, 580, 13, 361, 9659, 297, 6024, 29876, 742, 525, 1217, 2033, 29901, 13, 1678, 1596, 376, 1252, 11407, 17794, 13, 1678, 23283, 580, 13, 829, 401, 2565, 1457, 29958, 13, 13, 29966, 29886, 29958, 1266, 1283, 278, 17152, 29889, 3387, 11905, 529, 401, 29958, 26897, 829, 401, 29958, 304, 529, 401, 29958, 4907, 829, 401, 29958, 392, 372, 29915, 645, 24817, 366, 964, 278, 529, 401, 29958, 8000, 829, 401, 29958, 2425, 29889, 1533, 29886, 29958, 13, 13, 29966, 29886, 29958, 3492, 508, 884, 4337, 278, 529, 401, 16299, 15123, 1761, 29915, 829, 401, 29958, 322, 529, 401, 16299, 26381, 29915, 829, 401, 29958, 977, 264, 1280, 304, 3651, 577, 896, 9455, 29915, 29873, 2898, 274, 6797, 29889, 13001, 635, 29892, 366, 881, 4337, 963, 304, 263, 2295, 934, 470, 9335, 6389, 29889, 1533, 29886, 29958, 13, 13, 29966, 29886, 29958, 21140, 340, 338, 278, 4784, 29914, 14941, 287, 701, 1873, 310, 596, 775, 29901, 829, 29886, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 3166, 432, 29876, 558, 29889, 29926, 12609, 1053, 21830, 13, 3166, 432, 29876, 558, 29889, 29926, 12609, 29889, 13239, 29889, 2917, 1053, 12782, 13, 5215, 679, 3364, 13, 13, 26381, 29918, 9507, 353, 525, 26381, 29915, 13, 15123, 1761, 29918, 9507, 353, 525, 15123, 1761, 29915, 13, 13, 29937, 22351, 16140, 13, 6786, 353, 10650, 29918, 2080, 877, 10399, 596, 8952, 29901, 1495, 13, 5630, 353, 679, 3364, 29889, 657, 3364, 877, 10399, 596, 4800, 29901, 1495, 13, 13, 29937, 10811, 3568, 362, 310, 8260, 13, 26381, 29918, 517, 29918, 15060, 353, 1722, 29898, 26381, 29918, 9507, 29892, 525, 29878, 2824, 949, 580, 13, 13, 2158, 6629, 13, 2158, 525, 1576, 8260, 366, 526, 1048, 304, 9063, 526, 29901, 525, 13, 2158, 8260, 29918, 517, 29918, 15060, 13, 2158, 6629, 13, 2158, 525, 6132, 366, 864, 304, 6773, 304, 1065, 1438, 8260, 17901, 13, 13, 26897, 353, 6629, 13, 8000, 9659, 451, 297, 6024, 29891, 742, 525, 4099, 742, 525, 3582, 742, 525, 29876, 742, 525, 1217, 2033, 29901, 13, 1678, 9659, 353, 10650, 29918, 2080, 877, 29979, 470, 405, 29901, 525, 467, 13609, 580, 13, 1678, 565, 9659, 297, 6024, 29876, 742, 525, 1217, 2033, 29901, 13, 4706, 1596, 525, 1252, 11407, 856, 29915, 13, 4706, 23283, 580, 13, 1678, 25342, 9659, 297, 6024, 29891, 742, 525, 4099, 742, 525, 3582, 2033, 29901, 13, 4706, 6773, 13, 1678, 1683, 29901, 13, 4706], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 29871, 13, 1678, 835, 9330, 29901, 13, 1678, 11597, 29891, 911, 278, 4944, 1108, 322, 24656, 278, 2183, 5132, 775, 29889, 512, 2325, 3386, 573, 16705, 322, 385, 16710, 1873, 310, 278, 775, 29889, 13, 13, 1678, 835, 9705, 415, 29901, 13, 1678, 894, 29901, 529, 29886, 29958, 29902, 5456, 445, 2471, 304, 788, 777, 2295, 304, 263, 7452, 546, 4742, 29889, 29871, 739, 1736, 1532, 541, 278, 3353, 1404, 1881, 8845, 4004, 313, 3582, 470, 694, 4004, 29897, 2444, 263, 2217, 4473, 29891, 21106, 29886, 29958, 13, 13, 29966, 29886, 29958, 3624, 727, 263, 2253, 982, 306, 1033, 505, 2309, 372, 29973, 829, 29886, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 3166, 432, 29876, 558, 29889, 29926, 12609, 1053, 21830, 13, 3166, 432, 29876, 558, 29889, 29926, 12609, 29889, 13239, 29889, 2917, 1053, 12782, 13, 5215, 679, 3364, 13, 13, 29937, 29954, 4201, 16140, 13, 6786, 353, 10650, 29918, 2080, 703, 10399, 596, 8952, 29901, 1159, 13, 5630, 353, 679, 3364, 29889, 657, 3364, 703, 10399, 596, 4800, 29901, 1159, 13, 13, 29937, 16376, 3568, 362, 310, 8260, 13, 26381, 353, 1722, 703, 26381, 29908, 1919, 376, 29878, 1159, 13, 26381, 29918, 517, 29918, 15060, 353, 8260, 29889, 949, 580, 13, 2158, 5124, 13, 2158, 376, 1576, 8260, 366, 526, 1048, 304, 9063, 526, 29901, 376, 13, 2158, 8260, 29918, 517, 29918, 15060, 13, 2158, 5124, 13, 2158, 376, 6132, 366, 864, 304, 6773, 304, 1065, 1438, 8260, 3026, 13, 26897, 353, 10650, 29918, 2080, 703, 29979, 470, 405, 29901, 16521, 13, 1678, 565, 9659, 297, 6024, 29876, 3788, 1217, 3788, 29940, 3788, 6632, 3788, 3782, 2033, 29901, 13, 9651, 1596, 376, 1252, 11407, 17794, 13, 9651, 23283, 580, 13, 8000, 9659, 451, 297, 6024, 29891, 3788, 29979, 3788, 3582, 742, 29908, 8241, 613, 29915, 21143, 3788, 29876, 3788, 29940, 3788, 6632, 3788, 3782, 3788, 1217, 2033, 29901, 13, 1678, 1596, 376, 13919, 14542, 625, 29892, 3967, 1449, 29908, 13, 1678, 9659, 353, 10650, 29918, 2080, 703, 29979, 470, 405, 29901, 16521, 13, 1678, 565, 9659, 297, 6024, 29876, 3788, 1217, 3788, 29940, 3788, 6632, 3788, 3782, 2033, 29901, 13, 9651, 1596, 376, 1252, 11407, 17794, 13, 9651, 23283, 580, 13, 1678, 25342, 9659, 297, 6024, 29891, 3788, 29979, 3788, 3582, 742, 29908, 8241, 613, 29915, 21143, 2033, 29901, 13, 9651, 6773, 13, 13, 29937, 6585, 263, 934, 2000, 2381, 436, 1761, 607, 756, 263, 1051, 310, 9224, 304, 6623, 13, 2541, 1722, 877, 15123, 1761, 1495, 408, 297, 1445, 29901, 13, 1678, 363, 3495, 297, 297, 1445, 29901, 13, 9651, 1018, 29901, 13, 462, 1678, 1596, 376, 5531, 292, 373, 29901, 613, 3495, 29892, 13, 462, 1678, 396, 17918, 304, 9224, 297, 4607, 1761, 13, 462, 1678, 2906, 353, 21830, 29898, 3069, 29922, 3069, 29889, 17010, 3285, 29871, 1404, 29922, 6786, 29892, 4800, 29922, 5630, 29897, 13, 462, 1678, 2906, 29889, 3150, 580, 13, 462, 1678, 2723, 353, 12782, 29898, 3359, 29897, 13, 462, 1678, 396, 14959, 29879, 363, 263, 934, 4257, 8260, 411, 278, 1051, 310, 8260, 304, 1065, 13, 462, 1678, 5528, 3487, 353, 1722, 877, 26381, 1495, 13, 462, 1678, 731, 29918, 9006, 353, 5528, 3487, 29889, 949, 580, 13, 462, 1678, 2723, 29889, 1359, 29898, 842, 29918, 9006, 29892, 3402, 543, 842, 1159, 13, 462, 1678, 2723, 29889, 15060, 580, 13, 462, 1678, 2906, 29889, 5358, 580, 13, 462, 1678, 1596, 376, 26010, 29901, 613, 3495, 13, 9651, 5174, 8960, 29892, 29872, 29901, 1596, 376, 2392, 29901, 613, 321, 13, 9651, 6773, 13, 829, 401, 2565, 1457, 29958, 13, 29871, 13, 13, 673, 29901, 529, 29886, 29958, 3492, 508, 679, 8177, 310, 278, 937, 29901, 1533, 29886, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 26897, 353, 10650, 29918, 2080, 703, 29979, 470, 405, 29901, 376, 467, 13609, 580, 13, 361, 9659, 297, 6024, 29876, 742, 525, 1217, 2033, 29901, 13, 1678, 1596, 376, 1252, 11407, 17794, 13, 1678, 23283, 580, 13, 829, 401, 2565, 1457, 29958, 13, 13, 29966, 29886, 29958, 1266, 1283, 278, 17152, 29889, 3387, 11905, 529, 401, 29958, 26897, 829, 401, 29958, 304, 529, 401, 29958, 4907, 829, 401, 29958, 392, 372, 29915, 645, 24817, 366, 964, 278, 529, 401, 29958, 8000, 829, 401, 29958, 2425, 29889, 1533, 29886, 29958, 13, 13, 29966, 29886, 29958, 3492, 508, 884, 4337, 278, 529, 401, 16299, 15123, 1761, 29915, 829, 401, 29958, 322, 529, 401, 16299, 26381, 29915, 829, 401, 29958, 977, 264, 1280, 304, 3651, 577, 896, 9455, 29915, 29873, 2898, 274, 6797, 29889, 13001, 635, 29892, 366, 881, 4337, 963, 304, 263, 2295, 934, 470, 9335, 6389, 29889, 1533, 29886, 29958, 13, 13, 29966, 29886, 29958, 21140, 340, 338, 278, 4784, 29914, 14941, 287, 701, 1873, 310, 596, 775, 29901, 829, 29886, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 3166, 432, 29876, 558, 29889, 29926, 12609, 1053, 21830, 13, 3166, 432, 29876, 558, 29889, 29926, 12609, 29889, 13239, 29889, 2917, 1053, 12782, 13, 5215, 679, 3364, 13, 13, 26381, 29918, 9507, 353, 525, 26381, 29915, 13, 15123, 1761, 29918, 9507, 353, 525, 15123, 1761, 29915, 13, 13, 29937, 22351, 16140, 13, 6786, 353, 10650, 29918, 2080, 877, 10399, 596, 8952, 29901, 1495, 13, 5630, 353, 679, 3364, 29889, 657, 3364, 877, 10399, 596, 4800, 29901, 1495, 13, 13, 29937, 10811, 3568, 362, 310, 8260, 13, 26381, 29918, 517, 29918, 15060, 353, 1722, 29898, 26381, 29918, 9507, 29892, 525, 29878, 2824, 949, 580, 13, 13, 2158, 6629, 13, 2158, 525, 1576, 8260, 366, 526, 1048, 304, 9063, 526, 29901, 525, 13, 2158, 8260, 29918, 517, 29918, 15060, 13, 2158, 6629, 13, 2158, 525, 6132, 366, 864, 304, 6773, 304, 1065, 1438, 8260, 17901, 13, 13, 26897, 353, 6629, 13, 8000, 9659, 451, 297, 6024, 29891, 742, 525, 4099, 742, 525, 3582, 742, 525, 29876, 742, 525, 1217, 2033, 29901, 13, 1678, 9659, 353, 10650, 29918, 2080, 877, 29979, 470, 405, 29901, 525, 467, 13609, 580, 13, 1678, 565, 9659, 297, 6024, 29876, 742, 525, 1217, 2033, 29901, 13, 4706, 1596, 525, 1252, 11407, 856, 29915, 13, 4706, 23283, 580, 13, 1678, 25342, 9659, 297, 6024, 29891, 742, 525, 4099, 742, 525, 3582, 2033, 29901, 13, 4706, 6773, 13, 1678, 1683, 29901, 13, 4706]}\n",
            "Tokenized Test Dataset Sample: {'prompt': 'Question: <p>I\\'ve been writing basic Python scripts for a while now to help process data or automate some task but I\\'ve decided I should start picking up unit testing and objective orientated programming (the vast majority of my scripts so far have been procedural).</p>\\n\\n<p>As a starter I decided to follow along with Uncle Bob\\'s <a href=\"http://butunclebob.com/ArticleS.UncleBob.TheBowlingGameKata\" rel=\"nofollow\">bowling scoring kata</a> to try and get my mind around TDD and the idea of writing the absolute minimal code at every step to either make the test go red or green (plus any refactoring steps).</p>\\n\\n<p>As it\\'s a bare bones example of following TDD the main program doesn\\'t actually have an entry point other than via the tests.</p>\\n\\n<p>Things that stand out to my beginner\\'s eye:</p>\\n\\n<ul>\\n<li><p>There are a lot of <code>self</code>s which look like a lot of visual clutter when I read through the code. Is there a better way of doing this? I think it\\'s the density of them that really gets me so I wasn\\'t sure if I could abstract some of them somehow?</p></li>\\n<li><p><code>unittest</code> seems to have a lot of boilerplate. I had a play with <code>nose</code> a while back which seemed to strip a lot of that out but I thought it might be a good idea to start properly with <code>unittest</code> until I have a use case for anything that <code>nose</code> (or any other library) offers. </p></li>\\n</ul>\\n\\n<h3>bowling_game.py</h3>\\n\\n<pre><code>#!/usr/bin/env python\\n\\nclass Game:\\n\\n  _rolls = [0] * 21\\n  _current_roll = 0\\n\\n  def roll(self, pins):\\n    self._rolls[self._current_roll] = pins\\n    self._current_roll += 1\\n\\n  def score(self):\\n    score = 0\\n    frame_index = 0\\n    for frame in range(0, 10):\\n      if self._is_strike(frame_index):\\n        score += 10 + self._strike_bonus(frame_index)\\n        frame_index += 1\\n      elif self._is_spare(frame_index):\\n        score += 10 + self._spare_bonus(frame_index)\\n        frame_index += 2\\n      else:\\n        score += self._rolls[frame_index] + self._rolls[frame_index + 1]\\n        frame_index += 2\\n    return score\\n\\n  def _sum_of_balls_in_frame(self, frame_index):\\n    return self._rolls[frame_index] + self._rolls[frame_index + 1]\\n\\n  def _spare_bonus(self, frame_index):\\n    return self._rolls[frame_index + 2]\\n\\n  def _strike_bonus(self, frame_index):\\n    return self._rolls[frame_index + 1] + self._rolls[frame_index + 2]\\n\\n  def _is_spare(self, frame_index):\\n    return self._rolls[frame_index] + self._rolls[frame_index + 1] == 10\\n\\n  def _is_strike(self, frame_index):\\n    return self._rolls[frame_index] == 10\\n</code></pre>\\n\\n<h3>bowling_game_test.py</h3>\\n\\n<pre><code>#!/usr/bin/env python\\n\\nimport unittest\\n\\nfrom bowling_game import Game\\n\\nclass BowlingGameTest(unittest.TestCase):\\n\\n  def setUp(self):\\n    self.g = Game()\\n\\n  def roll_many(self, rolls, pins):\\n    for roll in range(0, rolls):\\n      self.g.roll(pins)\\n\\n  def roll_spare(self):\\n    self.g.roll(5)\\n    self.g.roll(5)\\n\\n  def roll_strike(self):\\n    self.g.roll(10)\\n\\n  def test_gutter_game(self):\\n    rolls = 20\\n    pins = 0\\n    self.roll_many(rolls, pins)\\n    self.assertEquals(self.g.score(),0)\\n\\n  def test_all_ones(self):\\n    rolls = 20\\n    pins = 1\\n    self.roll_many(rolls, pins)\\n    self.assertEquals(self.g.score(),20)\\n\\n  def test_one_spare(self):\\n    self.roll_spare()\\n    self.g.roll(3)\\n    self.roll_many(17, 0)\\n    self.assertEquals(self.g.score(),16)\\n\\n  def test_one_strike(self):\\n    self.roll_strike()\\n    self.g.roll(3)\\n    self.g.roll(4)\\n    self.roll_many(16, 0)\\n    self.assertEquals(self.g.score(),24)\\n\\n  def test_perfect_game(self):\\n    self.roll_many(12, 10)\\n    self.assertEquals(self.g.score(),300)\\n\\nif __name__ == \\'__main__\\':\\n    unittest.main()\\n</code></pre>\\n\\n<p>The <a href=\"https://github.com/tomelliff/bowling-kata-python/commits/master\" rel=\"nofollow\">commit history</a> is available on GitHub if anyone fancies taking a look at that to see where I might have gone better with the red -> green -> refactor cycle.</p>\\n \\n\\n Answer: <p>It doesn\\'t look like too many <code>self</code>s to me.</p>\\n\\n<hr>\\n\\n<blockquote>\\n<pre><code>class Game:\\n\\n  _rolls = [0] * 21\\n  _current_roll = 0\\n\\n  ...\\n</code></pre>\\n</blockquote>\\n\\n<p>3 things right off the bat:</p>\\n\\n<ol>\\n<li>What\\'s with the blank line between <code>class Game:</code> and <code>_rolls = [0] * 21</code>?</li>\\n<li>You are using 2 spaces to indent. Use 4 spaces.</li>\\n<li><p>Shouldn\\'t this be in the <code>__init__</code> function?:</p>\\n\\n<blockquote>\\n<pre><code>_rolls = [0] * 21\\n_current_roll = 0\\n</code></pre>\\n</blockquote></li>\\n</ol>\\n\\n<p>So it would look like:</p>\\n\\n<pre><code>class Game:\\n    def __init__(self):\\n        self._rolls = [0] * 21\\n        self._current_roll = 0\\n\\n    def roll(self, pins):\\n        self._rolls[self._current_roll] = pins\\n        self._current_roll += 1\\n\\n    ...\\n</code></pre>\\n \\n\\n This is a question and answer from a forum where users review and improve the code of other users. Please output the original code, a summary of the critique, and the revised code using the format ORIGINAL: [write original code here] CRITIQUE: [write critique here] REVISED: [write revision code here]. \\n\\n', 'response': \"\\nOriginal: \\nclass Game:\\n\\n  _rolls = [0] * 21\\n  _current_roll = 0\\n\\n  def roll(self, pins):\\n    self._rolls[self._current_roll] = pins\\n    self._current_roll += 1\\n\\n  def score(self):\\n    score = 0\\n    frame_index = 0\\n    for frame in range(0, 10):\\n      if self._is_strike(frame_index):\\n        score += 10 + self._strike_bonus(frame_index)\\n        frame_index += 1\\n      elif self._is_spare(frame_index):\\n        score += 10 + self._spare_bonus(frame_index)\\n        frame_index += 2\\n      else:\\n        score += self._rolls[frame_index] + self._rolls[frame_index + 1]\\n        frame_index += 2\\n    return score\\n\\n  def _sum_of_balls_in_frame(self, frame_index):\\n    return self._rolls[frame_index] + self._rolls[frame_index + 1]\\n\\n  def _spare_bonus(self, frame_index):\\n    return self._rolls[frame_index + 2]\\n\\n  def _strike_bonus(self, frame_index):\\n    return self._rolls[frame_index + 1] + self._rolls[frame_index + 2]\\n\\n  def _is_spare(self, frame_index):\\n    return self._rolls[frame_index] + self._rolls[frame_index + 1] == 10\\n\\n  def _is_strike(self, frame_index):\\n    return self._rolls[frame_index] == 10\\n\\nCritique: \\n3 things right off the bat:\\n\\n1. What's with the blank line between class Game: and _rolls = [0] * 21?\\n2. You are using 2 spaces to indent. Use 4 spaces.\\n3. Shouldn't this be in the __init__ function?: _rolls = [0] * 21 _current_roll = 0\\n\\nRevised: \\nclass Game:\\n    def __init__(self):\\n        self._rolls = [0] * 21\\n        self._current_roll = 0\\n\\n    def roll(self, pins):\\n        self._rolls[self._current_roll] = pins\\n        self._current_roll += 1\\n\\n    def score(self):\\n        score = 0\\n        frame_index = 0\\n        for frame in range(0, 10):\\n            if self._is_strike(frame_index):\\n                score += 10 + self._strike_bonus(frame_index)\\n                frame_index += 1\\n            elif self._is_spare(frame_index):\\n                score += 10 + self._spare_bonus(frame_index)\\n                frame_index += 2\\n            else:\\n                score += self._rolls[frame_index] + self._rolls[frame_index + 1]\\n                frame_index += 2\\n        return score\\n\\n    def _sum_of_balls_in_frame(self, frame_index):\\n        return self._rolls[frame_index] + self._rolls[frame_index + 1]\\n\\n    def _spare_bonus(self, frame_index):\\n        return self._rolls[frame_index + 2]\\n\\n    def _strike_bonus(self, frame_index):\\n        return self._rolls[frame_index + 1] + self._rolls[frame_index + 2]\\n\\n    def _is_spare(self, frame_index):\\n        return self._rolls[frame_index] + self._rolls[frame_index + 1] == 10\\n\\n    def _is_strike(self, frame_index):\\n        return self._rolls[frame_index] == 10\", 'input_ids': [1, 29871, 13, 1678, 835, 9330, 29901, 13, 1678, 11597, 29891, 911, 278, 4944, 1108, 322, 24656, 278, 2183, 5132, 775, 29889, 512, 2325, 3386, 573, 16705, 322, 385, 16710, 1873, 310, 278, 775, 29889, 13, 13, 1678, 835, 9705, 415, 29901, 13, 1678, 894, 29901, 529, 29886, 29958, 29902, 29915, 345, 1063, 5007, 6996, 5132, 12078, 363, 263, 1550, 1286, 304, 1371, 1889, 848, 470, 3345, 403, 777, 3414, 541, 306, 29915, 345, 8459, 306, 881, 1369, 5839, 292, 701, 5190, 6724, 322, 12091, 7769, 630, 8720, 313, 1552, 13426, 13638, 310, 590, 12078, 577, 2215, 505, 1063, 6449, 3631, 467, 829, 29886, 29958, 13, 13, 29966, 29886, 29958, 2887, 263, 380, 4254, 306, 8459, 304, 1101, 3412, 411, 29108, 7991, 29915, 29879, 529, 29874, 2822, 543, 1124, 597, 4187, 348, 2841, 29890, 711, 29889, 510, 29914, 9986, 2512, 29903, 29889, 2525, 2841, 29362, 29889, 1576, 29933, 340, 1847, 14199, 29968, 532, 29908, 1104, 543, 4043, 1013, 17729, 1847, 26654, 413, 532, 829, 29874, 29958, 304, 1018, 322, 679, 590, 3458, 2820, 323, 7858, 322, 278, 2969, 310, 5007, 278, 8380, 13114, 775, 472, 1432, 4331, 304, 2845, 1207, 278, 1243, 748, 2654, 470, 7933, 313, 11242, 738, 28559, 292, 6576, 467, 829, 29886, 29958, 13, 13, 29966, 29886, 29958, 2887, 372, 29915, 29879, 263, 16079, 289, 2873, 1342, 310, 1494, 323, 7858, 278, 1667, 1824, 1838, 29915, 29873, 2869, 505, 385, 6251, 1298, 916, 1135, 3025, 278, 6987, 21106, 29886, 29958, 13, 13, 29966, 29886, 29958, 1349, 886, 393, 2317, 714, 304, 590, 26605, 29915, 29879, 10977, 29901, 829, 29886, 29958, 13, 13, 29966, 352, 29958, 13, 29966, 492, 5299, 29886, 29958, 8439, 526, 263, 3287, 310, 529, 401, 29958, 1311, 829, 401, 29958, 29879, 607, 1106, 763, 263, 3287, 310, 7604, 1067, 6463, 746, 306, 1303, 1549, 278, 775, 29889, 1317, 727, 263, 2253, 982, 310, 2599, 445, 29973, 306, 1348, 372, 29915, 29879, 278, 9027, 310, 963, 393, 2289, 4947, 592, 577, 306, 9007, 29915, 29873, 1854, 565, 306, 1033, 9846, 777, 310, 963, 10431, 29973, 829, 29886, 2565, 492, 29958, 13, 29966, 492, 5299, 29886, 5299, 401, 29958, 348, 27958, 829, 401, 29958, 2444, 304, 505, 263, 3287, 310, 1045, 3955, 2341, 29889, 306, 750, 263, 1708, 411, 529, 401, 29958, 29876, 852, 829, 401, 29958, 263, 1550, 1250, 607, 6140, 304, 17820, 263, 3287, 310, 393, 714, 541, 306, 2714, 372, 1795, 367, 263, 1781, 2969, 304, 1369, 6284, 411, 529, 401, 29958, 348, 27958, 829, 401, 29958, 2745, 306, 505, 263, 671, 1206, 363, 3099, 393, 529, 401, 29958, 29876, 852, 829, 401, 29958, 313, 272, 738, 916, 3489, 29897, 16688, 29889, 1533, 29886, 2565, 492, 29958, 13, 829, 352, 29958, 13, 13, 29966, 29882, 29941, 29958, 17729, 1847, 29918, 11802, 29889, 2272, 829, 29882, 29941, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 29937, 14708, 4855, 29914, 2109, 29914, 6272, 3017, 13, 13, 1990, 8448, 29901, 13, 13, 29871, 903, 1245, 29879, 353, 518, 29900, 29962, 334, 29871, 29906, 29896, 13, 29871, 903, 3784, 29918, 1245, 353, 29871, 29900, 13, 13, 29871, 822, 9679, 29898, 1311, 29892, 282, 1144, 1125, 13, 1678, 1583, 3032, 1245, 29879, 29961, 1311, 3032, 3784, 29918, 1245, 29962, 353, 282, 1144, 13, 1678, 1583, 3032, 3784, 29918, 1245, 4619, 29871, 29896, 13, 13, 29871, 822, 8158, 29898, 1311, 1125, 13, 1678, 8158, 353, 29871, 29900, 13, 1678, 3515, 29918, 2248, 353, 29871, 29900, 13, 1678, 363, 3515, 297, 3464, 29898, 29900, 29892, 29871, 29896, 29900, 1125, 13, 418, 565, 1583, 3032, 275, 29918, 303, 20995, 29898, 2557, 29918, 2248, 1125, 13, 4706, 8158, 4619, 29871, 29896, 29900, 718, 1583, 3032, 303, 20995, 29918, 6718, 375, 29898, 2557, 29918, 2248, 29897, 13, 4706, 3515, 29918, 2248, 4619, 29871, 29896, 13, 418, 25342, 1583, 3032, 275, 29918, 1028, 598, 29898, 2557, 29918, 2248, 1125, 13, 4706, 8158, 4619, 29871, 29896, 29900, 718, 1583, 3032, 1028, 598, 29918, 6718, 375, 29898, 2557, 29918, 2248, 29897, 13, 4706, 3515, 29918, 2248, 4619, 29871, 29906, 13, 418, 1683, 29901, 13, 4706, 8158, 4619, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 29962, 718, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29896, 29962, 13, 4706, 3515, 29918, 2248, 4619, 29871, 29906, 13, 1678, 736, 8158, 13, 13, 29871, 822, 903, 2083, 29918, 974, 29918, 2135, 29879, 29918, 262, 29918, 2557, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 29962, 718, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29896, 29962, 13, 13, 29871, 822, 903, 1028, 598, 29918, 6718, 375, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29906, 29962, 13, 13, 29871, 822, 903, 303, 20995, 29918, 6718, 375, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29896, 29962, 718, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29906, 29962, 13, 13, 29871, 822, 903, 275, 29918, 1028, 598, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 29962, 718, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29896, 29962, 1275, 29871, 29896, 29900, 13, 13, 29871, 822, 903, 275, 29918, 303, 20995, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 29962, 1275, 29871, 29896, 29900, 13, 829, 401, 2565, 1457, 29958, 13, 13, 29966, 29882, 29941, 29958, 17729, 1847, 29918, 11802, 29918, 1688, 29889, 2272, 829, 29882, 29941, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 29937, 14708, 4855, 29914, 2109, 29914, 6272, 3017, 13, 13, 5215, 443, 27958, 13, 13, 3166, 12580, 1847, 29918, 11802, 1053, 8448, 13, 13, 1990, 13432, 1847, 14199, 3057, 29898, 348, 27958, 29889, 3057, 8259, 1125, 13, 13, 29871, 822, 731, 3373, 29898, 1311, 1125, 13, 1678, 1583, 29889, 29887, 353, 8448, 580, 13, 13, 29871, 822, 9679, 29918, 13011, 29898, 1311, 29892, 9679, 29879, 29892, 282, 1144, 1125, 13, 1678, 363, 9679, 297, 3464, 29898, 29900, 29892, 9679, 29879, 1125, 13, 418, 1583, 29889, 29887, 29889], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 29871, 13, 1678, 835, 9330, 29901, 13, 1678, 11597, 29891, 911, 278, 4944, 1108, 322, 24656, 278, 2183, 5132, 775, 29889, 512, 2325, 3386, 573, 16705, 322, 385, 16710, 1873, 310, 278, 775, 29889, 13, 13, 1678, 835, 9705, 415, 29901, 13, 1678, 894, 29901, 529, 29886, 29958, 29902, 29915, 345, 1063, 5007, 6996, 5132, 12078, 363, 263, 1550, 1286, 304, 1371, 1889, 848, 470, 3345, 403, 777, 3414, 541, 306, 29915, 345, 8459, 306, 881, 1369, 5839, 292, 701, 5190, 6724, 322, 12091, 7769, 630, 8720, 313, 1552, 13426, 13638, 310, 590, 12078, 577, 2215, 505, 1063, 6449, 3631, 467, 829, 29886, 29958, 13, 13, 29966, 29886, 29958, 2887, 263, 380, 4254, 306, 8459, 304, 1101, 3412, 411, 29108, 7991, 29915, 29879, 529, 29874, 2822, 543, 1124, 597, 4187, 348, 2841, 29890, 711, 29889, 510, 29914, 9986, 2512, 29903, 29889, 2525, 2841, 29362, 29889, 1576, 29933, 340, 1847, 14199, 29968, 532, 29908, 1104, 543, 4043, 1013, 17729, 1847, 26654, 413, 532, 829, 29874, 29958, 304, 1018, 322, 679, 590, 3458, 2820, 323, 7858, 322, 278, 2969, 310, 5007, 278, 8380, 13114, 775, 472, 1432, 4331, 304, 2845, 1207, 278, 1243, 748, 2654, 470, 7933, 313, 11242, 738, 28559, 292, 6576, 467, 829, 29886, 29958, 13, 13, 29966, 29886, 29958, 2887, 372, 29915, 29879, 263, 16079, 289, 2873, 1342, 310, 1494, 323, 7858, 278, 1667, 1824, 1838, 29915, 29873, 2869, 505, 385, 6251, 1298, 916, 1135, 3025, 278, 6987, 21106, 29886, 29958, 13, 13, 29966, 29886, 29958, 1349, 886, 393, 2317, 714, 304, 590, 26605, 29915, 29879, 10977, 29901, 829, 29886, 29958, 13, 13, 29966, 352, 29958, 13, 29966, 492, 5299, 29886, 29958, 8439, 526, 263, 3287, 310, 529, 401, 29958, 1311, 829, 401, 29958, 29879, 607, 1106, 763, 263, 3287, 310, 7604, 1067, 6463, 746, 306, 1303, 1549, 278, 775, 29889, 1317, 727, 263, 2253, 982, 310, 2599, 445, 29973, 306, 1348, 372, 29915, 29879, 278, 9027, 310, 963, 393, 2289, 4947, 592, 577, 306, 9007, 29915, 29873, 1854, 565, 306, 1033, 9846, 777, 310, 963, 10431, 29973, 829, 29886, 2565, 492, 29958, 13, 29966, 492, 5299, 29886, 5299, 401, 29958, 348, 27958, 829, 401, 29958, 2444, 304, 505, 263, 3287, 310, 1045, 3955, 2341, 29889, 306, 750, 263, 1708, 411, 529, 401, 29958, 29876, 852, 829, 401, 29958, 263, 1550, 1250, 607, 6140, 304, 17820, 263, 3287, 310, 393, 714, 541, 306, 2714, 372, 1795, 367, 263, 1781, 2969, 304, 1369, 6284, 411, 529, 401, 29958, 348, 27958, 829, 401, 29958, 2745, 306, 505, 263, 671, 1206, 363, 3099, 393, 529, 401, 29958, 29876, 852, 829, 401, 29958, 313, 272, 738, 916, 3489, 29897, 16688, 29889, 1533, 29886, 2565, 492, 29958, 13, 829, 352, 29958, 13, 13, 29966, 29882, 29941, 29958, 17729, 1847, 29918, 11802, 29889, 2272, 829, 29882, 29941, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 29937, 14708, 4855, 29914, 2109, 29914, 6272, 3017, 13, 13, 1990, 8448, 29901, 13, 13, 29871, 903, 1245, 29879, 353, 518, 29900, 29962, 334, 29871, 29906, 29896, 13, 29871, 903, 3784, 29918, 1245, 353, 29871, 29900, 13, 13, 29871, 822, 9679, 29898, 1311, 29892, 282, 1144, 1125, 13, 1678, 1583, 3032, 1245, 29879, 29961, 1311, 3032, 3784, 29918, 1245, 29962, 353, 282, 1144, 13, 1678, 1583, 3032, 3784, 29918, 1245, 4619, 29871, 29896, 13, 13, 29871, 822, 8158, 29898, 1311, 1125, 13, 1678, 8158, 353, 29871, 29900, 13, 1678, 3515, 29918, 2248, 353, 29871, 29900, 13, 1678, 363, 3515, 297, 3464, 29898, 29900, 29892, 29871, 29896, 29900, 1125, 13, 418, 565, 1583, 3032, 275, 29918, 303, 20995, 29898, 2557, 29918, 2248, 1125, 13, 4706, 8158, 4619, 29871, 29896, 29900, 718, 1583, 3032, 303, 20995, 29918, 6718, 375, 29898, 2557, 29918, 2248, 29897, 13, 4706, 3515, 29918, 2248, 4619, 29871, 29896, 13, 418, 25342, 1583, 3032, 275, 29918, 1028, 598, 29898, 2557, 29918, 2248, 1125, 13, 4706, 8158, 4619, 29871, 29896, 29900, 718, 1583, 3032, 1028, 598, 29918, 6718, 375, 29898, 2557, 29918, 2248, 29897, 13, 4706, 3515, 29918, 2248, 4619, 29871, 29906, 13, 418, 1683, 29901, 13, 4706, 8158, 4619, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 29962, 718, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29896, 29962, 13, 4706, 3515, 29918, 2248, 4619, 29871, 29906, 13, 1678, 736, 8158, 13, 13, 29871, 822, 903, 2083, 29918, 974, 29918, 2135, 29879, 29918, 262, 29918, 2557, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 29962, 718, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29896, 29962, 13, 13, 29871, 822, 903, 1028, 598, 29918, 6718, 375, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29906, 29962, 13, 13, 29871, 822, 903, 303, 20995, 29918, 6718, 375, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29896, 29962, 718, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29906, 29962, 13, 13, 29871, 822, 903, 275, 29918, 1028, 598, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 29962, 718, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 718, 29871, 29896, 29962, 1275, 29871, 29896, 29900, 13, 13, 29871, 822, 903, 275, 29918, 303, 20995, 29898, 1311, 29892, 3515, 29918, 2248, 1125, 13, 1678, 736, 1583, 3032, 1245, 29879, 29961, 2557, 29918, 2248, 29962, 1275, 29871, 29896, 29900, 13, 829, 401, 2565, 1457, 29958, 13, 13, 29966, 29882, 29941, 29958, 17729, 1847, 29918, 11802, 29918, 1688, 29889, 2272, 829, 29882, 29941, 29958, 13, 13, 29966, 1457, 5299, 401, 29958, 29937, 14708, 4855, 29914, 2109, 29914, 6272, 3017, 13, 13, 5215, 443, 27958, 13, 13, 3166, 12580, 1847, 29918, 11802, 1053, 8448, 13, 13, 1990, 13432, 1847, 14199, 3057, 29898, 348, 27958, 29889, 3057, 8259, 1125, 13, 13, 29871, 822, 731, 3373, 29898, 1311, 1125, 13, 1678, 1583, 29889, 29887, 353, 8448, 580, 13, 13, 29871, 822, 9679, 29918, 13011, 29898, 1311, 29892, 9679, 29879, 29892, 282, 1144, 1125, 13, 1678, 363, 9679, 297, 3464, 29898, 29900, 29892, 9679, 29879, 1125, 13, 418, 1583, 29889, 29887, 29889]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32,  # Rank of the update matrices\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Target specific modules\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "gNWtwPcCu8y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqXJisHHvIDm",
        "outputId": "79e0346e-caeb-4d90-cd5e-8e1170c267e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 33,554,432 || all params: 3,533,967,360 || trainable%: 0.9494833591219133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJCbk7SMvSZQ",
        "outputId": "80b0b93a-ef76-4c2f-bffd-4421e1f487b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Models_LLM_Project/mistral-7b-lora-it-code-optimize-v1\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=32,  # Increase if memory allows\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=False,\n",
        "    report_to=\"wandb\",  # Disable reporting to external tools like WandB\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOHPz5doxUOH",
        "outputId": "272f59fb-1956-46f3-ccd5-a4366f36a75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = default_data_collator"
      ],
      "metadata": {
        "id": "-At6dpdkykzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pynq5ycJymva",
        "outputId": "83fd9e0a-f659-4c21-9757-2755e02d95b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:449: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "_3aG21fJ3OD0",
        "outputId": "d41dbe56-d9f1-497f-be17-caa4362a5d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeepakuday23\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241127_044157-zr6goiuf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/deepakuday23/huggingface/runs/zr6goiuf' target=\"_blank\">/content/drive/MyDrive/Models_LLM_Project/mistral-7b-lora-it-code-optimize-v1</a></strong> to <a href='https://wandb.ai/deepakuday23/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/deepakuday23/huggingface' target=\"_blank\">https://wandb.ai/deepakuday23/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/deepakuday23/huggingface/runs/zr6goiuf' target=\"_blank\">https://wandb.ai/deepakuday23/huggingface/runs/zr6goiuf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='708' max='708' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [708/708 2:40:09, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.923100</td>\n",
              "      <td>0.934524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.930200</td>\n",
              "      <td>0.923848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.906000</td>\n",
              "      <td>0.918745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.908700</td>\n",
              "      <td>0.914725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.926200</td>\n",
              "      <td>0.911887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.878600</td>\n",
              "      <td>0.909861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.901000</td>\n",
              "      <td>0.907660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.872100</td>\n",
              "      <td>0.905228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.877700</td>\n",
              "      <td>0.903675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.891100</td>\n",
              "      <td>0.902968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.885600</td>\n",
              "      <td>0.902014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.864900</td>\n",
              "      <td>0.900840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.900095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.859800</td>\n",
              "      <td>0.899716</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=708, training_loss=0.902474259252602, metrics={'train_runtime': 9622.7245, 'train_samples_per_second': 2.36, 'train_steps_per_second': 0.074, 'total_flos': 9.244028078621983e+17, 'train_loss': 0.902474259252602, 'epoch': 2.993261989694808})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the LoRA adapters\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Models_LLM_Project/mistral-7b-lora-it-code-optimize-v1\")\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Models_LLM_Project/mistral-7b-lora-it-code-optimize-v1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQi5NtTV3q7f",
        "outputId": "21f74c31-5e00-4228-a549-1c56954fb678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Models_LLM_Project/mistral-7b-lora-it-code-optimize-v1/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Models_LLM_Project/mistral-7b-lora-it-code-optimize-v1/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Models_LLM_Project/mistral-7b-lora-it-code-optimize-v1/tokenizer.model',\n",
              " '/content/drive/MyDrive/Models_LLM_Project/mistral-7b-lora-it-code-optimize-v1/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# Load the base model with 4-bit quantization\n",
        "# Load the model with 4-bit quantization\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-hf\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Load the LoRA adapters\n",
        "model = PeftModel.from_pretrained(model, \"/content/drive/MyDrive/Models_LLM_Project/mistral-7b-lora-it-code-optimize-v1\")\n",
        "\n",
        "# Set to evaluation mode\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ba0bc2a0f4694e40b80041e341d98c40",
            "1780f57865f94360a96d2b2f28e096f9",
            "12995321365544cda86f34fc0c4a5af8",
            "d7a83a48e8634521bafa93038e54fc62",
            "94f6c2e3c49a442d97cdb042349e8a72",
            "d09dbbbe501d491fa5b67cbfa9528b7d",
            "9e8cb17ce13c428584657b714ea3d323",
            "ee3ff5bf9e5849b48960f396cf084ae5",
            "49ac5b8e52464a0781f417ddfeb38524",
            "432f83d3f56149868fbda8d19a8272d8",
            "04ff0b1dce964195a0b7da84b9ecfb5d"
          ]
        },
        "id": "wSqJjVIA35jn",
        "outputId": "d30d37c9-6c6e-4dd9-e361-331e1fce7b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba0bc2a0f4694e40b80041e341d98c40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py:556: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  adapters_weights = torch.load(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaSdpaAttention(\n",
              "              (q_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt):\n",
        "    \"\"\"\n",
        "    Generates a response from the model for a given prompt.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=1024,\n",
        "        temperature=0.2,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        repetition_penalty=1.2,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = generated_text[len(prompt):].strip()\n",
        "    return response"
      ],
      "metadata": {
        "id": "T5XpyuhI4NYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompt\n",
        "# Define the final zero-shot prompt\n",
        "prompt = \"\"\"\n",
        "### Task:\n",
        "Analyze the provided problem and optimize the given Python code. Provide constructive feedback and generate an improved version of the code.\n",
        "\n",
        "### Prompt:\n",
        "# I need suggestions for optimizing this recursive solution to generate Fibonacci numbers.\n",
        "# The current implementation is inefficient for large numbers. I'd like to improve its performance:\n",
        "\n",
        "'''\n",
        "Generate the nth Fibonacci number.\n",
        "The Fibonacci sequence is defined as:\n",
        "F(n) = F(n-1) + F(n-2), where F(0) = 0 and F(1) = 1\n",
        "'''\n",
        "\n",
        "def fibonacci(n):\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    else:\n",
        "        return fibonacci(n-1) + fibonacci(n-2)\n",
        "\n",
        "# Test the function\n",
        "print(fibonacci(10))\n",
        "\n",
        "### Instructions:\n",
        "1. Read and understand the original code and its problem statement.\n",
        "2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
        "3. Rewrite the code to address the critique.\n",
        "4. Begin your critique with \"Critique:\" and your revised code with \"Revised Code:\".\n",
        "\n",
        "##Response:\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Generate response\n",
        "response = generate_response(prompt)\n",
        "\n",
        "# Print the response\n",
        "print(\"Generated Response:\\n\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nthdN3584QvU",
        "outputId": "46f5cdf6-f84e-4729-9277-23f2ed7d98c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response:\n",
            " ```python\n",
            "Critique:\n",
            "This program has two major issues that can be addressed by using recursion instead of iteration. Firstly, it uses too many nested loops which makes the program slow when dealing with larger values of `n`. Secondly, it does not use any data structures such as lists or arrays which would allow us to store multiple values at once rather than having to calculate them one after another each time we call the function.\n",
            "\n",
            "To fix these problems we will rewrite our algorithm so that it only calls itself twice (once per loop). We also introduce some new variables into play - `i` represents how far through our list/array we are currently looking while `j` keeps track of what value should come next based on previous ones already seen beforehand; finally there exists yet another variable called `k`, which stores whatever result comes out from combining both `i`'s & `j`'s together!\n",
            "\n",
            "Revised Code:\n",
            "def fibonaccci_recursive(n):\n",
            "\tif n == 0:\n",
            "\t\treturn 0\n",
            "\telif n < 0:\n",
            "\t\traise ValueError(\"Negative input\")\n",
            "\telse:\n",
            "\t\tif n > 1: # If n >= 2 then recurse again until you get back down below 2\n",
            "\t\t\treturn fibonacccci_recursive(n-1)+fibonacccci_recursive(n-2)\n",
            "\t\telse: # Else just do normal calculation without calling recursively anymore\n",
            "\t\t\treturn n+1\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompt\n",
        "# Define the final zero-shot prompt\n",
        "prompt = \"\"\"\n",
        "### Task:\n",
        "Analyze the provided problem and optimize the given Python code. Provide constructive feedback and generate an improved version of the code.\n",
        "\n",
        "### Prompt:\n",
        "# I need suggestions for optimizing this recursive solution to generate Fibonacci numbers.\n",
        "# The current implementation is inefficient for large numbers. I'd like to improve its performance:\n",
        "\n",
        "'''\n",
        "Generate the nth Fibonacci number.\n",
        "The Fibonacci sequence is defined as:\n",
        "F(n) = F(n-1) + F(n-2), where F(0) = 0 and F(1) = 1\n",
        "'''\n",
        "\n",
        "def fibonacci(n):\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    else:\n",
        "        return fibonacci(n-1) + fibonacci(n-2)\n",
        "\n",
        "# Test the function\n",
        "print(fibonacci(10))\n",
        "\n",
        "### Instructions:\n",
        "1. Read and understand the original code and its problem statement.\n",
        "2. Provide a critique of the code, highlighting inefficiencies and areas for improvement.\n",
        "3. Rewrite the code to address the critique.\n",
        "4. Begin your critique with \"Critique:\" and your revised code with \"Revised Code:\".\n",
        "\n",
        "##Response:\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Generate response\n",
        "response = generate_response(prompt)\n",
        "\n",
        "# Print the response\n",
        "print(\"Generated Response:\\n\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPqINYsDgcA_",
        "outputId": "ee479924-a491-4636-99ad-217daea5ae25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response:\n",
            " <pre><code>class Solution:\n",
            "    def __init__(self):\n",
            "        self._cache = {}\n",
            "    \n",
            "    @staticmethod\n",
            "    def fibonacci_number(n):\n",
            "        \"\"\"Returns the nth Fibonacci number.\"\"\"\n",
            "        \n",
            "        # Check cache first\n",
            "        try:\n",
            "            return Solution()._cache[n]\n",
            "            \n",
            "        except KeyError:\n",
            "            pass\n",
            "                     \n",
            "        # If not found then calculate it recursively\n",
            "        elif n &gt;= 1:\n",
            "            return (Solution()).fibonacci_number((n - 1)) \\\n",
            "                + (Solution()).fibonacci_number((n - 2))\n",
            "</code></pre>\n",
            "\n",
            "<p>This class has two methods.</p>\n",
            "\n",
            "<ol>\n",
            "<li>A static method <code>fibonacci_number()</code>, which calculates the next Fibonacci number based on the previous ones stored in the cache.</li>\n",
            "<li>A private instance method <code>__init__()</code>. This initializes the cache dictionary by setting default values for all keys that don’t exist yet.</li>\n",
            "</ol>\n",
            "\n",
            "<hr>\n",
            "\n",
            "<blockquote>\n",
            "<pre><code>&gt;&gt;&gt; Solution().fibonacci_number(5)\n",
            "8\n",
            "&gt;&gt;&gt; Solution().fibonacci_number(6)\n",
            "13\n",
            "&gt;&gt;&gt; Solution().fibonacci_number(-1)\n",
            "Traceback (most recent call last):   File &quot;/usr/lib/python3.7/site-packages/ipykernel\\_terminal.py\", line 195, in runfile   exec(compile(input(), name, 'exec'), namespace)   File &quot;/home/user/.local/share/jupyter/runtime/nbserver-16168--profile-&lt;some random string&gt;\\aconda3\\envs\\myenv&quot;, line 10, in exec   from . import mymodule   File &quot;/home/user/.local/share/jupyter/runtime/nbserver-16168--profile-&lt;some random string&gt;\\aconda3\\envs\\myenv\\mymodule.py&quot;, line 1, in &lt;module&gt;   from .solution import Solution   File &quot;/home/user/.local/share/jupyter/runtime/nbserver-16168--profile-&lt;some random string&gt;\\aconda3\\envs\\myenv\\mymodule.py&quot;, line 10, in &lt;module&gt;   from typing import Dict   File &quot;/home/user/.local/share/jupyter/runtime/nbserver-16168--profile-&lt;some random string&gt;\\aconda3\\envs\\myenv\\typing.py&quot;, line 1, in &lt;module&gt;   from collections import namedtuple   File &quot;/home/user/.local/share/jupyter/runtime/nbserver-16168--profile-&lt;some random string&gt;\\aconda3\\envs\\myenv\\collections.py&quot;, line 1, in &lt;module&gt;   from itertools import count   File &quot;/home/user/.local/share/jupyter/runtime/nbserver-16168--profile-&lt;some random string&gt;\\aconda3\\envs\\myenv\\itertools.py&quot;, line 1, in &lt;module&gt;   from collections import deque   File &quot;/home/user/.local/share/jupyter/runtime/nbserver-16168--profile-&lt;some random string&gt;\\aconda3\\envs\\myenv\\deque.py&quot;, line 1, in &lt;module&gt;   from queue import Queue   File &quot;/home/user/.local/share/jupyter/runtime/nbserver-16168--profile-&lt;some random string&gt;\\aconda3\\envs\\myenv\\queue.py&quot;, line 1, in &lt;module&gt;   from functools import wraps   File &quot;/home/user/.local/share/jupyter/runtime/\n"
          ]
        }
      ]
    }
  ]
}